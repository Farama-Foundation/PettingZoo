<!doctype html>
<html class="no-js" lang="en" data-content_root="../../../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark">
    <meta name="description" content="">
    <meta property="og:title" content="PettingZoo Documentation" />
    <meta property="og:type" content="website" />
    <meta property="og:description" content="" />
    <meta property="og:url" content="https://pettingzoo.farama.org/tutorials/agilerl/MADDPG.html" /><meta name="twitter:card" content="summary_large_image"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../../../genindex/" /><link rel="search" title="Search" href="../../../search/" /><link rel="next" title="AgileRL: Implementing MATD3" href="../MATD3/" /><link rel="prev" title="AgileRL: Implementing DQN - Curriculum Learning and Self-play" href="../DQN/" />
        <link rel="canonical" href="https://pettingzoo.farama.org/tutorials/agilerl/MADDPG.html" />

    <link rel="shortcut icon" href="../../../_static/favicon.png"/><!-- Generated with Sphinx 7.4.7 and Furo 2023.08.19.dev1 -->
        <title>AgileRL: Implementing MADDPG - PettingZoo Documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo.css?v=3e7f4c72" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo-extensions.css?v=49cbaffd" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    <header class="farama-header" aria-label="Farama header">
      <div class="farama-header__container">
        <div class="farama-header__left--mobile">
          <label class="nav-overlay-icon" for="__navigation">
            <div class="visually-hidden">Toggle site navigation sidebar</div>
            <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
              <defs></defs>
              <line x1="0.5" y1="4" x2="23.5" y2="4"></line>
              <line x1="0.232" y1="12" x2="23.5" y2="12"></line>
              <line x1="0.232" y1="20" x2="23.5" y2="20"></line>
            </svg>
          </label>
        </div>
        <div class="farama-header__left farama-header__center--mobile">
          <a href="../../../">
              <img class="farama-header__logo only-light" src="../../../_static/img/PettingZoo.svg" alt="Light Logo"/>
              <img class="farama-header__logo only-dark" src="../../../_static/img/PettingZoo_White.svg" alt="Dark Logo"/>
            <span class="farama-header__title">PettingZoo Documentation</span>
          </a>
        </div>
        <div class="farama-header__right">
          <div class="farama-header-menu">
            <button class="farama-header-menu__btn" aria-label="Open Farama Menu" aria-expanded="false" aria-haspopup="true" aria-controls="farama-menu">
              <img class="farama-black-logo-invert" src="../../../_static/img/farama-logo-header.svg">
              <svg viewBox="0 0 24 24" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <polyline style="stroke-linecap: round; stroke-linejoin: round; fill: none; stroke-width: 2px;" points="1 7 12 18 23 7"></polyline>
              </svg>
            </button>
            <div class="farama-header-menu-container farama-hidden" aria-hidden="true" id="farama-menu">
              <div class="farama-header-menu__header">
                <a href="https://farama.org">
                  <img class="farama-header-menu__logo farama-white-logo-invert" src="../../../_static/img/farama_solid_white.svg" alt="Farama Foundation logo">
                  <span>Farama Foundation</span>
                </a>
                <div class="farama-header-menu-header__right">
                  <button id="farama-close-menu">
                    <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" fill="none" stroke="currentColor"
                      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon-close">
                      <line x1="3" y1="21" x2="21" y2="3"></line>
                      <line x1="3" y1="3" x2="21" y2="21"></line>
                    </svg>
                  </button>
                </div>
              </div>
              <div class="farama-header-menu__body">
                <!-- Response from farama.org/api/projects.json -->
              </div>
            </div>
          </div>
        </div>
      </div>
    </header>

    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<div class="page">
  <!--<header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../../"><div class="brand">PettingZoo Documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>-->
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="farama-sidebar__title" href="../../../">
      <img class="farama-header__logo only-light" src="../../../_static/img/PettingZoo.svg" alt="Light Logo"/>
      <img class="farama-header__logo only-dark" src="../../../_static/img/PettingZoo_White.svg" alt="Dark Logo"/>
    <span class="farama-header__title">PettingZoo Documentation</span>
  </a><form class="sidebar-search-container" method="get" action="../../../search/" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../content/basic_usage/">Basic Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../content/environment_creation/">Environment Creation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../content/environment_tests/">Testing Environments</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api/aec/">AEC API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/parallel/">Parallel API</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api/wrappers/">Wrappers</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Wrappers</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/wrappers/pz_wrappers/">PettingZoo Wrappers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/wrappers/supersuit_wrappers/">Supersuit Wrappers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/wrappers/shimmy_wrappers/">Shimmy Compatibility Wrappers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/utils/">Utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Environments</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../environments/atari/">Atari</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Atari</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/atari/basketball_pong/">Basketball Pong</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/atari/boxing/">Boxing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/atari/combat_plane/">Combat: Plane</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/atari/combat_tank/">Combat: Tank</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/atari/double_dunk/">Double Dunk</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/atari/entombed_competitive/">Emtombed: Competitive</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/atari/entombed_cooperative/">Emtombed: Cooperative</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/atari/flag_capture/">Flag Capture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/atari/foozpong/">Foozpong</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/atari/ice_hockey/">Ice Hockey</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/atari/joust/">Joust</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/atari/mario_bros/">Mario Bros</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/atari/maze_craze/">Maze Craze</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/atari/othello/">Othello</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/atari/pong/">Pong</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/atari/quadrapong/">Quadrapong</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/atari/space_invaders/">Space Invaders</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/atari/space_war/">Space War</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/atari/surround/">Surround</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/atari/tennis/">Tennis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/atari/video_checkers/">Video Checkers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/atari/volleyball_pong/">Volleyball Pong</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/atari/warlords/">Warlords</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/atari/wizard_of_wor/">Wizard of Wor</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../environments/butterfly/">Butterfly</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Butterfly</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/butterfly/cooperative_pong/">Cooperative Pong</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/butterfly/knights_archers_zombies/">Knights Archers Zombies (‘KAZ’)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/butterfly/pistonball/">Pistonball</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../environments/classic/">Classic</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of Classic</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/classic/chess/">Chess</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/classic/connect_four/">Connect Four</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/classic/gin_rummy/">Gin Rummy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/classic/go/">Go</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/classic/hanabi/">Hanabi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/classic/leduc_holdem/">Leduc Hold’em</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/classic/rps/">Rock Paper Scissors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/classic/texas_holdem_no_limit/">Texas Hold’em No Limit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/classic/texas_holdem/">Texas Hold’em</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/classic/tictactoe/">Tic Tac Toe</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../environments/mpe/">MPE</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of MPE</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/mpe/simple/">Simple</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/mpe/simple_adversary/">Simple Adversary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/mpe/simple_crypto/">Simple Crypto</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/mpe/simple_push/">Simple Push</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/mpe/simple_reference/">Simple Reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/mpe/simple_speaker_listener/">Simple Speaker Listener</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/mpe/simple_spread/">Simple Spread</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/mpe/simple_tag/">Simple Tag</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/mpe/simple_world_comm/">Simple World Comm</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../environments/sisl/">SISL</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of SISL</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/sisl/multiwalker/">Multiwalker</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/sisl/pursuit/">Pursuit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../environments/sisl/waterworld/">Waterworld</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../environments/third_party_envs/">Third-Party Environments</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="current">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../custom_environment/">Custom Environment Tutorial</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of Custom Environment Tutorial</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../custom_environment/1-project-structure/">Tutorial: Repository Structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../custom_environment/2-environment-logic/">Tutorial: Environment Logic</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../custom_environment/3-action-masking/">Tutorial: Action Masking</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../custom_environment/4-testing-your-environment/">Tutorial: Testing Your Environment</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../cleanrl/">CleanRL Tutorial</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of CleanRL Tutorial</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../cleanrl/implementing_PPO/">CleanRL: Implementing PPO</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../cleanrl/advanced_PPO/">CleanRL: Advanced PPO</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tianshou/">Tianshou Tutorial</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of Tianshou Tutorial</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tianshou/beginner/">Tianshou: Basic API Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tianshou/intermediate/">Tianshou: Training Agents</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tianshou/advanced/">Tianshou: CLI and Logging</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../rllib/">Ray RLlib Tutorial</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of Ray RLlib Tutorial</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../rllib/pistonball/">RLlib: PPO for Pistonball</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../rllib/holdem/">RLlib: DQN for Simple Poker</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../langchain/">LangChain Tutorial</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of LangChain Tutorial</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../langchain/langchain/">LangChain: Creating LLM agents</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../sb3/">Stable-Baselines3 Tutorial</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of Stable-Baselines3 Tutorial</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../sb3/kaz/">SB3: PPO for Knights-Archers-Zombies</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../sb3/waterworld/">SB3: PPO for Waterworld</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../sb3/connect_four/">SB3: Action Masked PPO for Connect Four</a></li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="../">AgileRL Tutorial</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle navigation of AgileRL Tutorial</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../DQN/">AgileRL: Implementing DQN - Curriculum Learning and Self-play</a></li>
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">AgileRL: Implementing MADDPG</a></li>
<li class="toctree-l2"><a class="reference internal" href="../MATD3/">AgileRL: Implementing MATD3</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Development</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/Farama-Foundation/PettingZoo">Github</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../release_notes/">Release Notes</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/Farama-Foundation/PettingZoo/tree/master/docs/">Contribute to the Docs</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main-container">

    

    

    <div class="main">
      <div class="content">
        <div class="article-container">
          <a href="#" class="back-to-top muted-link">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
              <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
            </svg>
            <span>Back to top</span>
          </a>
          <div class="content-icon-container">
      <div class="edit-this-page">
  <a class="muted-link" href="https://github.com/Farama-Foundation/PettingZoo/edit/master/docs/tutorials/agilerl/MADDPG.py" title="Edit this page">
    <svg aria-hidden="true" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <path d="M4 20h4l10.5 -10.5a1.5 1.5 0 0 0 -4 -4l-10.5 10.5v4" />
      <line x1="13.5" y1="6.5" x2="17.5" y2="10.5" />
    </svg>
    <span class="visually-hidden">Edit this page</span>
  </a>
</div><div class="theme-toggle-container theme-toggle-content">
              <button class="theme-toggle" title="Toggle color theme">
                <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
                <svg class="theme-icon-when-auto">
                  <use href="#svg-sun-half"></use>
                </svg>
                <svg class="theme-icon-when-dark">
                  <use href="#svg-moon"></use>
                </svg>
                <svg class="theme-icon-when-light">
                  <use href="#svg-sun"></use>
                </svg>
              </button>
            </div>
            <label class="toc-overlay-icon toc-content-icon" for="__toc">
              <div class="visually-hidden">Toggle table of contents sidebar</div>
              <i class="icon"><svg>
                  <use href="#svg-toc"></use>
                </svg></i>
            </label>
          </div>
          <article role="main">
            
            <section class="tex2jax_ignore mathjax_ignore" id="agilerl-implementing-maddpg">
<h1>AgileRL: Implementing MADDPG<a class="headerlink" href="#agilerl-implementing-maddpg" title="Link to this heading">¶</a></h1>
<p>This tutorial shows how to train an <a class="reference external" href="https://agilerl.readthedocs.io/en/latest/api/algorithms/maddpg.html">MADDPG</a> agent on the <a class="reference external" href="https://pettingzoo.farama.org/environments/atari/space_invaders/">space invaders</a> atari environment.</p>
<section id="what-is-maddpg">
<h2>What is MADDPG?<a class="headerlink" href="#what-is-maddpg" title="Link to this heading">¶</a></h2>
<p><a class="reference external" href="https://agilerl.readthedocs.io/en/latest/api/algorithms/maddpg.html">MADDPG</a> (Multi-Agent Deep Deterministic Policy Gradients) extends the <a class="reference external" href="https://agilerl.readthedocs.io/en/latest/api/algorithms/ddpg.html">DDPG</a> (Deep Deterministic Policy Gradients) algorithm to enable cooperative or competitive training of multiple agents in complex environments, enhancing the stability and convergence of the learning process through decentralized actor and centralized critic architectures. For further information on MADDPG, check out the AgileRL <a class="reference external" href="https://agilerl.readthedocs.io/en/latest/api/algorithms/maddpg.html">documentation</a>.</p>
<section id="can-i-use-it">
<h3>Can I use it?<a class="headerlink" href="#can-i-use-it" title="Link to this heading">¶</a></h3>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>Action Space</p></th>
<th class="head"><p>Observation Space</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Discrete</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-odd"><td><p>Continuous</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
<section id="environment-setup">
<h2>Environment Setup<a class="headerlink" href="#environment-setup" title="Link to this heading">¶</a></h2>
<p>To follow this tutorial, you will need to install the dependencies shown below. It is recommended to use a newly-created virtual environment to avoid dependency conflicts.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>agilerl==0.1.22; python_version &gt;= &#39;3.9&#39;
pettingzoo[classic,atari,mpe]&gt;=1.23.1
SuperSuit&gt;=3.9.0
torch&gt;=2.0.1
numpy&gt;=1.24.2
tqdm&gt;=4.65.0
fastrand==1.3.0
gymnasium&gt;=0.28.1
imageio&gt;=2.31.1
Pillow&gt;=9.5.0
PyYAML&gt;=5.4.1
wandb&gt;=0.13.10
</pre></div>
</div>
</section>
<section id="code">
<h2>Code<a class="headerlink" href="#code" title="Link to this heading">¶</a></h2>
<section id="train-multiple-agents-using-maddpg">
<h3>Train multiple agents using MADDPG<a class="headerlink" href="#train-multiple-agents-using-maddpg" title="Link to this heading">¶</a></h3>
<p>The following code should run without any issues. The comments are designed to help you understand how to use PettingZoo with AgileRL. If you have any questions, please feel free to ask in the <a class="reference external" href="https://discord.com/invite/eB8HyTA2ux">Discord server</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;This tutorial shows how to train an MADDPG agent on the space invaders atari environment.</span>

<span class="sd">Authors: Michael (https://github.com/mikepratt1), Nick (https://github.com/nicku-a)</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">supersuit</span> <span class="k">as</span> <span class="nn">ss</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">agilerl.components.multi_agent_replay_buffer</span> <span class="kn">import</span> <span class="n">MultiAgentReplayBuffer</span>
<span class="kn">from</span> <span class="nn">agilerl.hpo.mutation</span> <span class="kn">import</span> <span class="n">Mutations</span>
<span class="kn">from</span> <span class="nn">agilerl.hpo.tournament</span> <span class="kn">import</span> <span class="n">TournamentSelection</span>
<span class="kn">from</span> <span class="nn">agilerl.utils.utils</span> <span class="kn">import</span> <span class="n">initialPopulation</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">trange</span>

<span class="kn">from</span> <span class="nn">pettingzoo.atari</span> <span class="kn">import</span> <span class="n">space_invaders_v2</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;===== AgileRL MADDPG Demo =====&quot;</span><span class="p">)</span>

    <span class="c1"># Define the network configuration</span>
    <span class="n">NET_CONFIG</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;arch&quot;</span><span class="p">:</span> <span class="s2">&quot;cnn&quot;</span><span class="p">,</span>  <span class="c1"># Network architecture</span>
        <span class="s2">&quot;hidden_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span>  <span class="c1"># Network hidden size</span>
        <span class="s2">&quot;channel_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span>  <span class="c1"># CNN channel size</span>
        <span class="s2">&quot;kernel_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>  <span class="c1"># CNN kernel size</span>
        <span class="s2">&quot;stride_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>  <span class="c1"># CNN stride size</span>
        <span class="s2">&quot;normalize&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>  <span class="c1"># Normalize image from range [0,255] to [0,1]</span>
    <span class="p">}</span>

    <span class="c1"># Define the initial hyperparameters</span>
    <span class="n">INIT_HP</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;POPULATION_SIZE&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="s2">&quot;ALGO&quot;</span><span class="p">:</span> <span class="s2">&quot;MADDPG&quot;</span><span class="p">,</span>  <span class="c1"># Algorithm</span>
        <span class="c1"># Swap image channels dimension from last to first [H, W, C] -&gt; [C, H, W]</span>
        <span class="s2">&quot;CHANNELS_LAST&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s2">&quot;BATCH_SIZE&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>  <span class="c1"># Batch size</span>
        <span class="s2">&quot;LR_ACTOR&quot;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span>  <span class="c1"># Actor learning rate</span>
        <span class="s2">&quot;LR_CRITIC&quot;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span>  <span class="c1"># Critic learning rate</span>
        <span class="s2">&quot;GAMMA&quot;</span><span class="p">:</span> <span class="mf">0.95</span><span class="p">,</span>  <span class="c1"># Discount factor</span>
        <span class="s2">&quot;MEMORY_SIZE&quot;</span><span class="p">:</span> <span class="mi">10000</span><span class="p">,</span>  <span class="c1"># Max memory buffer size</span>
        <span class="s2">&quot;LEARN_STEP&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>  <span class="c1"># Learning frequency</span>
        <span class="s2">&quot;TAU&quot;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span>  <span class="c1"># For soft update of target parameters</span>
    <span class="p">}</span>

    <span class="c1"># Define the space invaders environment as a parallel environment</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">space_invaders_v2</span><span class="o">.</span><span class="n">parallel_env</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">INIT_HP</span><span class="p">[</span><span class="s2">&quot;CHANNELS_LAST&quot;</span><span class="p">]:</span>
        <span class="c1"># Environment processing for image based observations</span>
        <span class="n">env</span> <span class="o">=</span> <span class="n">ss</span><span class="o">.</span><span class="n">frame_skip_v0</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
        <span class="n">env</span> <span class="o">=</span> <span class="n">ss</span><span class="o">.</span><span class="n">clip_reward_v0</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">lower_bound</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">upper_bound</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">env</span> <span class="o">=</span> <span class="n">ss</span><span class="o">.</span><span class="n">color_reduction_v0</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;B&quot;</span><span class="p">)</span>
        <span class="n">env</span> <span class="o">=</span> <span class="n">ss</span><span class="o">.</span><span class="n">resize_v1</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">x_size</span><span class="o">=</span><span class="mi">84</span><span class="p">,</span> <span class="n">y_size</span><span class="o">=</span><span class="mi">84</span><span class="p">)</span>
        <span class="n">env</span> <span class="o">=</span> <span class="n">ss</span><span class="o">.</span><span class="n">frame_stack_v1</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
    <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

    <span class="c1"># Configure the multi-agent algo input arguments</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">state_dim</span> <span class="o">=</span> <span class="p">[</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span><span class="o">.</span><span class="n">n</span> <span class="k">for</span> <span class="n">agent</span> <span class="ow">in</span> <span class="n">env</span><span class="o">.</span><span class="n">agents</span><span class="p">]</span>
        <span class="n">one_hot</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
        <span class="n">state_dim</span> <span class="o">=</span> <span class="p">[</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">agent</span> <span class="ow">in</span> <span class="n">env</span><span class="o">.</span><span class="n">agents</span><span class="p">]</span>
        <span class="n">one_hot</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">action_dim</span> <span class="o">=</span> <span class="p">[</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span><span class="o">.</span><span class="n">n</span> <span class="k">for</span> <span class="n">agent</span> <span class="ow">in</span> <span class="n">env</span><span class="o">.</span><span class="n">agents</span><span class="p">]</span>
        <span class="n">INIT_HP</span><span class="p">[</span><span class="s2">&quot;DISCRETE_ACTIONS&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">INIT_HP</span><span class="p">[</span><span class="s2">&quot;MAX_ACTION&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">INIT_HP</span><span class="p">[</span><span class="s2">&quot;MIN_ACTION&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
        <span class="n">action_dim</span> <span class="o">=</span> <span class="p">[</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">agent</span> <span class="ow">in</span> <span class="n">env</span><span class="o">.</span><span class="n">agents</span><span class="p">]</span>
        <span class="n">INIT_HP</span><span class="p">[</span><span class="s2">&quot;DISCRETE_ACTIONS&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">INIT_HP</span><span class="p">[</span><span class="s2">&quot;MAX_ACTION&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span><span class="o">.</span><span class="n">high</span> <span class="k">for</span> <span class="n">agent</span> <span class="ow">in</span> <span class="n">env</span><span class="o">.</span><span class="n">agents</span><span class="p">]</span>
        <span class="n">INIT_HP</span><span class="p">[</span><span class="s2">&quot;MIN_ACTION&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span><span class="o">.</span><span class="n">low</span> <span class="k">for</span> <span class="n">agent</span> <span class="ow">in</span> <span class="n">env</span><span class="o">.</span><span class="n">agents</span><span class="p">]</span>

    <span class="c1"># Pre-process image dimensions for pytorch convolutional layers</span>
    <span class="k">if</span> <span class="n">INIT_HP</span><span class="p">[</span><span class="s2">&quot;CHANNELS_LAST&quot;</span><span class="p">]:</span>
        <span class="n">state_dim</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span><span class="n">state_dim</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">state_dim</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">state_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">state_dim</span> <span class="ow">in</span> <span class="n">state_dim</span>
        <span class="p">]</span>

    <span class="c1"># Append number of agents and agent IDs to the initial hyperparameter dictionary</span>
    <span class="n">INIT_HP</span><span class="p">[</span><span class="s2">&quot;N_AGENTS&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">num_agents</span>
    <span class="n">INIT_HP</span><span class="p">[</span><span class="s2">&quot;AGENT_IDS&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">agents</span>

    <span class="c1"># Create a population ready for evolutionary hyper-parameter optimisation</span>
    <span class="n">pop</span> <span class="o">=</span> <span class="n">initialPopulation</span><span class="p">(</span>
        <span class="n">INIT_HP</span><span class="p">[</span><span class="s2">&quot;ALGO&quot;</span><span class="p">],</span>
        <span class="n">state_dim</span><span class="p">,</span>
        <span class="n">action_dim</span><span class="p">,</span>
        <span class="n">one_hot</span><span class="p">,</span>
        <span class="n">NET_CONFIG</span><span class="p">,</span>
        <span class="n">INIT_HP</span><span class="p">,</span>
        <span class="n">population_size</span><span class="o">=</span><span class="n">INIT_HP</span><span class="p">[</span><span class="s2">&quot;POPULATION_SIZE&quot;</span><span class="p">],</span>
        <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Configure the multi-agent replay buffer</span>
    <span class="n">field_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;state&quot;</span><span class="p">,</span> <span class="s2">&quot;action&quot;</span><span class="p">,</span> <span class="s2">&quot;reward&quot;</span><span class="p">,</span> <span class="s2">&quot;next_state&quot;</span><span class="p">,</span> <span class="s2">&quot;done&quot;</span><span class="p">]</span>
    <span class="n">memory</span> <span class="o">=</span> <span class="n">MultiAgentReplayBuffer</span><span class="p">(</span>
        <span class="n">INIT_HP</span><span class="p">[</span><span class="s2">&quot;MEMORY_SIZE&quot;</span><span class="p">],</span>
        <span class="n">field_names</span><span class="o">=</span><span class="n">field_names</span><span class="p">,</span>
        <span class="n">agent_ids</span><span class="o">=</span><span class="n">INIT_HP</span><span class="p">[</span><span class="s2">&quot;AGENT_IDS&quot;</span><span class="p">],</span>
        <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Instantiate a tournament selection object (used for HPO)</span>
    <span class="n">tournament</span> <span class="o">=</span> <span class="n">TournamentSelection</span><span class="p">(</span>
        <span class="n">tournament_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>  <span class="c1"># Tournament selection size</span>
        <span class="n">elitism</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># Elitism in tournament selection</span>
        <span class="n">population_size</span><span class="o">=</span><span class="n">INIT_HP</span><span class="p">[</span><span class="s2">&quot;POPULATION_SIZE&quot;</span><span class="p">],</span>  <span class="c1"># Population size</span>
        <span class="n">evo_step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="p">)</span>  <span class="c1"># Evaluate using last N fitness scores</span>

    <span class="c1"># Instantiate a mutations object (used for HPO)</span>
    <span class="n">mutations</span> <span class="o">=</span> <span class="n">Mutations</span><span class="p">(</span>
        <span class="n">algo</span><span class="o">=</span><span class="n">INIT_HP</span><span class="p">[</span><span class="s2">&quot;ALGO&quot;</span><span class="p">],</span>
        <span class="n">no_mutation</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>  <span class="c1"># Probability of no mutation</span>
        <span class="n">architecture</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>  <span class="c1"># Probability of architecture mutation</span>
        <span class="n">new_layer_prob</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>  <span class="c1"># Probability of new layer mutation</span>
        <span class="n">parameters</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>  <span class="c1"># Probability of parameter mutation</span>
        <span class="n">activation</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>  <span class="c1"># Probability of activation function mutation</span>
        <span class="n">rl_hp</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>  <span class="c1"># Probability of RL hyperparameter mutation</span>
        <span class="n">rl_hp_selection</span><span class="o">=</span><span class="p">[</span>
            <span class="s2">&quot;lr&quot;</span><span class="p">,</span>
            <span class="s2">&quot;learn_step&quot;</span><span class="p">,</span>
            <span class="s2">&quot;batch_size&quot;</span><span class="p">,</span>
        <span class="p">],</span>  <span class="c1"># RL hyperparams selected for mutation</span>
        <span class="n">mutation_sd</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>  <span class="c1"># Mutation strength</span>
        <span class="c1"># Define search space for each hyperparameter</span>
        <span class="n">min_lr</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span>
        <span class="n">max_lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
        <span class="n">min_learn_step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">max_learn_step</span><span class="o">=</span><span class="mi">120</span><span class="p">,</span>
        <span class="n">min_batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">max_batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
        <span class="n">agent_ids</span><span class="o">=</span><span class="n">INIT_HP</span><span class="p">[</span><span class="s2">&quot;AGENT_IDS&quot;</span><span class="p">],</span>  <span class="c1"># Agent IDs</span>
        <span class="n">arch</span><span class="o">=</span><span class="n">NET_CONFIG</span><span class="p">[</span><span class="s2">&quot;arch&quot;</span><span class="p">],</span>  <span class="c1"># MLP or CNN</span>
        <span class="n">rand_seed</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Define training loop parameters</span>
    <span class="n">max_episodes</span> <span class="o">=</span> <span class="mi">5</span>  <span class="c1"># Total episodes (default: 6000)</span>
    <span class="n">max_steps</span> <span class="o">=</span> <span class="mi">900</span>  <span class="c1"># Maximum steps to take in each episode</span>
    <span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1.0</span>  <span class="c1"># Starting epsilon value</span>
    <span class="n">eps_end</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># Final epsilon value</span>
    <span class="n">eps_decay</span> <span class="o">=</span> <span class="mf">0.995</span>  <span class="c1"># Epsilon decay</span>
    <span class="n">evo_epochs</span> <span class="o">=</span> <span class="mi">20</span>  <span class="c1"># Evolution frequency</span>
    <span class="n">evo_loop</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># Number of evaluation episodes</span>
    <span class="n">elite</span> <span class="o">=</span> <span class="n">pop</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># Assign a placeholder &quot;elite&quot; agent</span>

    <span class="c1"># Training loop</span>
    <span class="k">for</span> <span class="n">idx_epi</span> <span class="ow">in</span> <span class="n">trange</span><span class="p">(</span><span class="n">max_episodes</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">agent</span> <span class="ow">in</span> <span class="n">pop</span><span class="p">:</span>  <span class="c1"># Loop through population</span>
            <span class="n">state</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>  <span class="c1"># Reset environment at start of episode</span>
            <span class="n">agent_reward</span> <span class="o">=</span> <span class="p">{</span><span class="n">agent_id</span><span class="p">:</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">agent_id</span> <span class="ow">in</span> <span class="n">env</span><span class="o">.</span><span class="n">agents</span><span class="p">}</span>
            <span class="k">if</span> <span class="n">INIT_HP</span><span class="p">[</span><span class="s2">&quot;CHANNELS_LAST&quot;</span><span class="p">]:</span>
                <span class="n">state</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="n">agent_id</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">moveaxis</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">])</span>
                    <span class="k">for</span> <span class="n">agent_id</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">state</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                <span class="p">}</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_steps</span><span class="p">):</span>
                <span class="n">agent_mask</span> <span class="o">=</span> <span class="n">info</span><span class="p">[</span><span class="s2">&quot;agent_mask&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="s2">&quot;agent_mask&quot;</span> <span class="ow">in</span> <span class="n">info</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span>
                <span class="n">env_defined_actions</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">info</span><span class="p">[</span><span class="s2">&quot;env_defined_actions&quot;</span><span class="p">]</span>
                    <span class="k">if</span> <span class="s2">&quot;env_defined_actions&quot;</span> <span class="ow">in</span> <span class="n">info</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
                    <span class="k">else</span> <span class="kc">None</span>
                <span class="p">)</span>

                <span class="c1"># Get next action from agent</span>
                <span class="n">cont_actions</span><span class="p">,</span> <span class="n">discrete_action</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">getAction</span><span class="p">(</span>
                    <span class="n">state</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">agent_mask</span><span class="p">,</span> <span class="n">env_defined_actions</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">agent</span><span class="o">.</span><span class="n">discrete_actions</span><span class="p">:</span>
                    <span class="n">action</span> <span class="o">=</span> <span class="n">discrete_action</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">action</span> <span class="o">=</span> <span class="n">cont_actions</span>

                <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">termination</span><span class="p">,</span> <span class="n">truncation</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span>
                    <span class="n">action</span>
                <span class="p">)</span>  <span class="c1"># Act in environment</span>

                <span class="c1"># Image processing if necessary for the environment</span>
                <span class="k">if</span> <span class="n">INIT_HP</span><span class="p">[</span><span class="s2">&quot;CHANNELS_LAST&quot;</span><span class="p">]:</span>
                    <span class="n">state</span> <span class="o">=</span> <span class="p">{</span><span class="n">agent_id</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">agent_id</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">state</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
                    <span class="n">next_state</span> <span class="o">=</span> <span class="p">{</span>
                        <span class="n">agent_id</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">moveaxis</span><span class="p">(</span><span class="n">ns</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">])</span>
                        <span class="k">for</span> <span class="n">agent_id</span><span class="p">,</span> <span class="n">ns</span> <span class="ow">in</span> <span class="n">next_state</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                    <span class="p">}</span>

                <span class="c1"># Save experiences to replay buffer</span>
                <span class="n">memory</span><span class="o">.</span><span class="n">save2memory</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">cont_actions</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">termination</span><span class="p">)</span>

                <span class="c1"># Collect the reward</span>
                <span class="k">for</span> <span class="n">agent_id</span><span class="p">,</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">reward</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="n">agent_reward</span><span class="p">[</span><span class="n">agent_id</span><span class="p">]</span> <span class="o">+=</span> <span class="n">r</span>

                <span class="c1"># Learn according to learning frequency</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">memory</span><span class="o">.</span><span class="n">counter</span> <span class="o">%</span> <span class="n">agent</span><span class="o">.</span><span class="n">learn_step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span>
                    <span class="nb">len</span><span class="p">(</span><span class="n">memory</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">agent</span><span class="o">.</span><span class="n">batch_size</span>
                <span class="p">):</span>
                    <span class="n">experiences</span> <span class="o">=</span> <span class="n">memory</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
                        <span class="n">agent</span><span class="o">.</span><span class="n">batch_size</span>
                    <span class="p">)</span>  <span class="c1"># Sample replay buffer</span>
                    <span class="n">agent</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">experiences</span><span class="p">)</span>  <span class="c1"># Learn according to agent&#39;s RL algorithm</span>

                <span class="c1"># Update the state</span>
                <span class="k">if</span> <span class="n">INIT_HP</span><span class="p">[</span><span class="s2">&quot;CHANNELS_LAST&quot;</span><span class="p">]:</span>
                    <span class="n">next_state</span> <span class="o">=</span> <span class="p">{</span>
                        <span class="n">agent_id</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">ns</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
                        <span class="k">for</span> <span class="n">agent_id</span><span class="p">,</span> <span class="n">ns</span> <span class="ow">in</span> <span class="n">next_state</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                    <span class="p">}</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>

                <span class="c1"># Stop episode if any agents have terminated</span>
                <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">truncation</span><span class="o">.</span><span class="n">values</span><span class="p">())</span> <span class="ow">or</span> <span class="nb">any</span><span class="p">(</span><span class="n">termination</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
                    <span class="k">break</span>

            <span class="c1"># Save the total episode reward</span>
            <span class="n">score</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">agent_reward</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
            <span class="n">agent</span><span class="o">.</span><span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>

        <span class="c1"># Update epsilon for exploration</span>
        <span class="n">epsilon</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">eps_end</span><span class="p">,</span> <span class="n">epsilon</span> <span class="o">*</span> <span class="n">eps_decay</span><span class="p">)</span>

        <span class="c1"># Now evolve population if necessary</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">idx_epi</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">evo_epochs</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Evaluate population</span>
            <span class="n">fitnesses</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">agent</span><span class="o">.</span><span class="n">test</span><span class="p">(</span>
                    <span class="n">env</span><span class="p">,</span>
                    <span class="n">swap_channels</span><span class="o">=</span><span class="n">INIT_HP</span><span class="p">[</span><span class="s2">&quot;CHANNELS_LAST&quot;</span><span class="p">],</span>
                    <span class="n">max_steps</span><span class="o">=</span><span class="n">max_steps</span><span class="p">,</span>
                    <span class="n">loop</span><span class="o">=</span><span class="n">evo_loop</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">agent</span> <span class="ow">in</span> <span class="n">pop</span>
            <span class="p">]</span>

            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Episode </span><span class="si">{</span><span class="n">idx_epi</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">max_episodes</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Fitnesses: </span><span class="si">{</span><span class="p">[</span><span class="s2">&quot;</span><span class="si">%.2f</span><span class="s2">&quot;</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">fitness</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">fitness</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">fitnesses</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s1">&#39;100 fitness avgs: </span><span class="si">{</span><span class="p">[</span><span class="s2">&quot;</span><span class="si">%.2f</span><span class="s2">&quot;</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">agent</span><span class="o">.</span><span class="n">fitness</span><span class="p">[</span><span class="o">-</span><span class="mi">100</span><span class="p">:])</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">agent</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">pop</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span>
            <span class="p">)</span>

            <span class="c1"># Tournament selection and population mutation</span>
            <span class="n">elite</span><span class="p">,</span> <span class="n">pop</span> <span class="o">=</span> <span class="n">tournament</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">pop</span><span class="p">)</span>
            <span class="n">pop</span> <span class="o">=</span> <span class="n">mutations</span><span class="o">.</span><span class="n">mutation</span><span class="p">(</span><span class="n">pop</span><span class="p">)</span>

    <span class="c1"># Save the trained algorithm</span>
    <span class="n">path</span> <span class="o">=</span> <span class="s2">&quot;./models/MADDPG&quot;</span>
    <span class="n">filename</span> <span class="o">=</span> <span class="s2">&quot;MADDPG_trained_agent.pt&quot;</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">save_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
    <span class="n">elite</span><span class="o">.</span><span class="n">saveCheckpoint</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="watch-the-trained-agents-play">
<h3>Watch the trained agents play<a class="headerlink" href="#watch-the-trained-agents-play" title="Link to this heading">¶</a></h3>
<p>The following code allows you to load your saved MADDPG alogorithm from the previous training block, test the algorithms performance, and then visualise a number of episodes as a gif.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">imageio</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">supersuit</span> <span class="k">as</span> <span class="nn">ss</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">agilerl.algorithms.maddpg</span> <span class="kn">import</span> <span class="n">MADDPG</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span><span class="p">,</span> <span class="n">ImageDraw</span>

<span class="kn">from</span> <span class="nn">pettingzoo.atari</span> <span class="kn">import</span> <span class="n">space_invaders_v2</span>


<span class="c1"># Define function to return image</span>
<span class="k">def</span> <span class="nf">_label_with_episode_number</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">episode_num</span><span class="p">):</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>

    <span class="n">drawer</span> <span class="o">=</span> <span class="n">ImageDraw</span><span class="o">.</span><span class="n">Draw</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">128</span><span class="p">:</span>
        <span class="n">text_color</span> <span class="o">=</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">text_color</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">drawer</span><span class="o">.</span><span class="n">text</span><span class="p">(</span>
        <span class="p">(</span><span class="n">im</span><span class="o">.</span><span class="n">size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="mi">20</span><span class="p">,</span> <span class="n">im</span><span class="o">.</span><span class="n">size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="mi">18</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Episode: </span><span class="si">{</span><span class="n">episode_num</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="n">text_color</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">im</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

    <span class="c1"># Configure the environment</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">space_invaders_v2</span><span class="o">.</span><span class="n">parallel_env</span><span class="p">(</span><span class="n">render_mode</span><span class="o">=</span><span class="s2">&quot;rgb_array&quot;</span><span class="p">)</span>
    <span class="n">channels_last</span> <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># Needed for environments that use images as observations</span>
    <span class="k">if</span> <span class="n">channels_last</span><span class="p">:</span>
        <span class="c1"># Environment processing for image based observations</span>
        <span class="n">env</span> <span class="o">=</span> <span class="n">ss</span><span class="o">.</span><span class="n">frame_skip_v0</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
        <span class="n">env</span> <span class="o">=</span> <span class="n">ss</span><span class="o">.</span><span class="n">clip_reward_v0</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">lower_bound</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">upper_bound</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">env</span> <span class="o">=</span> <span class="n">ss</span><span class="o">.</span><span class="n">color_reduction_v0</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;B&quot;</span><span class="p">)</span>
        <span class="n">env</span> <span class="o">=</span> <span class="n">ss</span><span class="o">.</span><span class="n">resize_v1</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">x_size</span><span class="o">=</span><span class="mi">84</span><span class="p">,</span> <span class="n">y_size</span><span class="o">=</span><span class="mi">84</span><span class="p">)</span>
        <span class="n">env</span> <span class="o">=</span> <span class="n">ss</span><span class="o">.</span><span class="n">frame_stack_v1</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
    <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">state_dim</span> <span class="o">=</span> <span class="p">[</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span><span class="o">.</span><span class="n">n</span> <span class="k">for</span> <span class="n">agent</span> <span class="ow">in</span> <span class="n">env</span><span class="o">.</span><span class="n">agents</span><span class="p">]</span>
        <span class="n">one_hot</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
        <span class="n">state_dim</span> <span class="o">=</span> <span class="p">[</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">agent</span> <span class="ow">in</span> <span class="n">env</span><span class="o">.</span><span class="n">agents</span><span class="p">]</span>
        <span class="n">one_hot</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">action_dim</span> <span class="o">=</span> <span class="p">[</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span><span class="o">.</span><span class="n">n</span> <span class="k">for</span> <span class="n">agent</span> <span class="ow">in</span> <span class="n">env</span><span class="o">.</span><span class="n">agents</span><span class="p">]</span>
        <span class="n">discrete_actions</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">max_action</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">min_action</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
        <span class="n">action_dim</span> <span class="o">=</span> <span class="p">[</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">agent</span> <span class="ow">in</span> <span class="n">env</span><span class="o">.</span><span class="n">agents</span><span class="p">]</span>
        <span class="n">discrete_actions</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">max_action</span> <span class="o">=</span> <span class="p">[</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span><span class="o">.</span><span class="n">high</span> <span class="k">for</span> <span class="n">agent</span> <span class="ow">in</span> <span class="n">env</span><span class="o">.</span><span class="n">agents</span><span class="p">]</span>
        <span class="n">min_action</span> <span class="o">=</span> <span class="p">[</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span><span class="o">.</span><span class="n">low</span> <span class="k">for</span> <span class="n">agent</span> <span class="ow">in</span> <span class="n">env</span><span class="o">.</span><span class="n">agents</span><span class="p">]</span>

    <span class="c1"># Pre-process image dimensions for pytorch convolutional layers</span>
    <span class="k">if</span> <span class="n">channels_last</span><span class="p">:</span>
        <span class="n">state_dim</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span><span class="n">state_dim</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">state_dim</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">state_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">state_dim</span> <span class="ow">in</span> <span class="n">state_dim</span>
        <span class="p">]</span>

    <span class="c1"># Append number of agents and agent IDs to the initial hyperparameter dictionary</span>
    <span class="n">n_agents</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">num_agents</span>
    <span class="n">agent_ids</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">agents</span>

    <span class="c1"># Instantiate an MADDPG object</span>
    <span class="n">maddpg</span> <span class="o">=</span> <span class="n">MADDPG</span><span class="p">(</span>
        <span class="n">state_dim</span><span class="p">,</span>
        <span class="n">action_dim</span><span class="p">,</span>
        <span class="n">one_hot</span><span class="p">,</span>
        <span class="n">n_agents</span><span class="p">,</span>
        <span class="n">agent_ids</span><span class="p">,</span>
        <span class="n">max_action</span><span class="p">,</span>
        <span class="n">min_action</span><span class="p">,</span>
        <span class="n">discrete_actions</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Load the saved algorithm into the MADDPG object</span>
    <span class="n">path</span> <span class="o">=</span> <span class="s2">&quot;./models/MADDPG/MADDPG_trained_agent.pt&quot;</span>
    <span class="n">maddpg</span><span class="o">.</span><span class="n">loadCheckpoint</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

    <span class="c1"># Define test loop parameters</span>
    <span class="n">episodes</span> <span class="o">=</span> <span class="mi">10</span>  <span class="c1"># Number of episodes to test agent on</span>
    <span class="n">max_steps</span> <span class="o">=</span> <span class="mi">500</span>  <span class="c1"># Max number of steps to take in the environment in each episode</span>

    <span class="n">rewards</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># List to collect total episodic reward</span>
    <span class="n">frames</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># List to collect frames</span>
    <span class="n">indi_agent_rewards</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">agent_id</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">agent_id</span> <span class="ow">in</span> <span class="n">agent_ids</span>
    <span class="p">}</span>  <span class="c1"># Dictionary to collect inidivdual agent rewards</span>

    <span class="c1"># Test loop for inference</span>
    <span class="k">for</span> <span class="n">ep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">episodes</span><span class="p">):</span>
        <span class="n">state</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="n">agent_reward</span> <span class="o">=</span> <span class="p">{</span><span class="n">agent_id</span><span class="p">:</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">agent_id</span> <span class="ow">in</span> <span class="n">agent_ids</span><span class="p">}</span>
        <span class="n">score</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_steps</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">channels_last</span><span class="p">:</span>
                <span class="n">state</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="n">agent_id</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">moveaxis</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span>
                    <span class="k">for</span> <span class="n">agent_id</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">state</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                <span class="p">}</span>

            <span class="n">agent_mask</span> <span class="o">=</span> <span class="n">info</span><span class="p">[</span><span class="s2">&quot;agent_mask&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="s2">&quot;agent_mask&quot;</span> <span class="ow">in</span> <span class="n">info</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span>
            <span class="n">env_defined_actions</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">info</span><span class="p">[</span><span class="s2">&quot;env_defined_actions&quot;</span><span class="p">]</span>
                <span class="k">if</span> <span class="s2">&quot;env_defined_actions&quot;</span> <span class="ow">in</span> <span class="n">info</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
                <span class="k">else</span> <span class="kc">None</span>
            <span class="p">)</span>

            <span class="c1"># Get next action from agent</span>
            <span class="n">cont_actions</span><span class="p">,</span> <span class="n">discrete_action</span> <span class="o">=</span> <span class="n">maddpg</span><span class="o">.</span><span class="n">getAction</span><span class="p">(</span>
                <span class="n">state</span><span class="p">,</span>
                <span class="n">epsilon</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">agent_mask</span><span class="o">=</span><span class="n">agent_mask</span><span class="p">,</span>
                <span class="n">env_defined_actions</span><span class="o">=</span><span class="n">env_defined_actions</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">maddpg</span><span class="o">.</span><span class="n">discrete_actions</span><span class="p">:</span>
                <span class="n">action</span> <span class="o">=</span> <span class="n">discrete_action</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">action</span> <span class="o">=</span> <span class="n">cont_actions</span>

            <span class="c1"># Save the frame for this step and append to frames list</span>
            <span class="n">frame</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">()</span>
            <span class="n">frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_label_with_episode_number</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">episode_num</span><span class="o">=</span><span class="n">ep</span><span class="p">))</span>

            <span class="c1"># Take action in environment</span>
            <span class="n">state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">termination</span><span class="p">,</span> <span class="n">truncation</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

            <span class="c1"># Save agent&#39;s reward for this step in this episode</span>
            <span class="k">for</span> <span class="n">agent_id</span><span class="p">,</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">reward</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">agent_reward</span><span class="p">[</span><span class="n">agent_id</span><span class="p">]</span> <span class="o">+=</span> <span class="n">r</span>

            <span class="c1"># Determine total score for the episode and then append to rewards list</span>
            <span class="n">score</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">agent_reward</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

            <span class="c1"># Stop episode if any agents have terminated</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">truncation</span><span class="o">.</span><span class="n">values</span><span class="p">())</span> <span class="ow">or</span> <span class="nb">any</span><span class="p">(</span><span class="n">termination</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
                <span class="k">break</span>

        <span class="n">rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>

        <span class="c1"># Record agent specific episodic reward for each agent</span>
        <span class="k">for</span> <span class="n">agent_id</span> <span class="ow">in</span> <span class="n">agent_ids</span><span class="p">:</span>
            <span class="n">indi_agent_rewards</span><span class="p">[</span><span class="n">agent_id</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">agent_reward</span><span class="p">[</span><span class="n">agent_id</span><span class="p">])</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">15</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Episode: </span><span class="si">{</span><span class="n">ep</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">15</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Episodic Reward: &quot;</span><span class="p">,</span> <span class="n">rewards</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">agent_id</span><span class="p">,</span> <span class="n">reward_list</span> <span class="ow">in</span> <span class="n">indi_agent_rewards</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">agent_id</span><span class="si">}</span><span class="s2"> reward: </span><span class="si">{</span><span class="n">reward_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="c1"># Save the gif to specified path</span>
    <span class="n">gif_path</span> <span class="o">=</span> <span class="s2">&quot;./videos/&quot;</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">gif_path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">imageio</span><span class="o">.</span><span class="n">mimwrite</span><span class="p">(</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;./videos/&quot;</span><span class="p">,</span> <span class="s2">&quot;space_invaders.gif&quot;</span><span class="p">),</span> <span class="n">frames</span><span class="p">,</span> <span class="n">duration</span><span class="o">=</span><span class="mi">10</span>
    <span class="p">)</span>
</pre></div>
</div>
</section>
</section>
</section>

          </article>
        </div>
        <footer>
          
          <div class="related-pages">
            <a class="next-page" href="../MATD3/">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">AgileRL: Implementing MATD3</div>
              </div>
              <svg class="furo-related-icon">
                <use href="#svg-arrow-right"></use>
              </svg>
            </a>
            <a class="prev-page" href="../DQN/">
              <svg class="furo-related-icon">
                <use href="#svg-arrow-right"></use>
              </svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">AgileRL: Implementing DQN - Curriculum Learning and Self-play</div>
                
              </div>
            </a>
          </div>
          <div class="bottom-of-page">
            <div class="left-details">
              <div class="copyright">
                Copyright &#169; 2023 Farama Foundation
              </div>
              <!--
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            -->
            </div>
            <div class="right-details">
              <div class="icons">
                <a class="muted-link" href="https://github.com/Farama-Foundation/PettingZoo/"
                  aria-label="On GitHub">
                  <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16">
                    <path fill-rule="evenodd"
                      d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z">
                    </path>
                  </svg>
                </a>
              </div>
            </div>
          </div>
          
        </footer>
      </div>
      <aside class="toc-drawer">
        
        
        <div class="toc-sticky toc-scroll">
          <div class="toc-title-container">
            <span class="toc-title">
              On this page
            </span>
          </div>
          <div class="toc-tree-container">
            <div class="toc-tree">
              <ul>
<li><a class="reference internal" href="#">AgileRL: Implementing MADDPG</a><ul>
<li><a class="reference internal" href="#what-is-maddpg">What is MADDPG?</a><ul>
<li><a class="reference internal" href="#can-i-use-it">Can I use it?</a></li>
</ul>
</li>
<li><a class="reference internal" href="#environment-setup">Environment Setup</a></li>
<li><a class="reference internal" href="#code">Code</a><ul>
<li><a class="reference internal" href="#train-multiple-agents-using-maddpg">Train multiple agents using MADDPG</a></li>
<li><a class="reference internal" href="#watch-the-trained-agents-play">Watch the trained agents play</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
        
        
      </aside>
    </div>
  </div>
</div>
    <script>
      const toggleMenu = () => {
        const menuBtn = document.querySelector(".farama-header-menu__btn");
        const menuContainer = document.querySelector(".farama-header-menu-container");
        if (document.querySelector(".farama-header-menu").classList.contains("active")) {
          menuBtn.setAttribute("aria-expanded", "false");
          menuContainer.setAttribute("aria-hidden", "true");
        } else {
          menuBtn.setAttribute("aria-expanded", "true");
          menuContainer.setAttribute("aria-hidden", "false");
        }
        document.querySelector(".farama-header-menu").classList.toggle("active");
      }

      document.querySelector(".farama-header-menu__btn").addEventListener("click", toggleMenu);
      document.getElementById("farama-close-menu").addEventListener("click", toggleMenu);
    </script>

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-Q4EGMJ3R24"></script>
      <script>
        const enableGtag = () => {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-Q4EGMJ3R24');
        }
        (() => {
            if (!localStorage.getItem("acceptedCookieAlert")) {
                const boxElem = document.createElement("div");
                boxElem.classList.add("cookie-alert");
                const containerElem = document.createElement("div");
                containerElem.classList.add("cookie-alert__container");
                const textElem = document.createElement("p");
                textElem.innerHTML = `This page uses <a href="https://analytics.google.com/">
                                    Google Analytics</a> to collect statistics.`;
                                    containerElem.appendChild(textElem);

                const declineBtn = Object.assign(document.createElement("button"),
                  {
                    innerText: "Deny",
                    className: "farama-btn cookie-alert__button",
                    id: "cookie-alert__decline",
                  }
                );
                declineBtn.addEventListener("click", () => {
                  localStorage.setItem("acceptedCookieAlert", false);
                  boxElem.remove();
                });

                const acceptBtn = Object.assign(document.createElement("button"),
                  {
                    innerText: "Allow",
                    className: "farama-btn cookie-alert__button",
                    id: "cookie-alert__accept",
                  }
                );
                acceptBtn.addEventListener("click", () => {
                  localStorage.setItem("acceptedCookieAlert", true);
                  boxElem.remove();
                  enableGtag();
                });

                containerElem.appendChild(declineBtn);
                containerElem.appendChild(acceptBtn);
                boxElem.appendChild(containerElem);
                document.body.appendChild(boxElem);
            } else if (localStorage.getItem("acceptedCookieAlert") === "true") {
              enableGtag();
            }
        })()
      </script>

    <script src="../../../_static/documentation_options.js?v=4b4b37dc"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/scripts/furo.js?v=7660844c"></script>
    
    <script>

      const createProjectsList = (projects, displayImages) => {
        const ulElem = Object.assign(document.createElement('ul'),
          {
            className:'farama-header-menu-list',
          }
        )
        for (let project of projects) {
          const liElem = document.createElement("li");
          const aElem = Object.assign(document.createElement("a"),
            {
              href: project.link
            }
          );
          liElem.appendChild(aElem);
          if (displayImages) {
            const imgElem = Object.assign(document.createElement("img"),
              {
                src: project.image ? imagesBasepath + project.image : imagesBasepath + "/farama_black.svg",
                alt: `${project.name} logo`,
                className: "farama-black-logo-invert"
              }
            );
            aElem.appendChild(imgElem);
          }
          aElem.appendChild(document.createTextNode(project.name));
          ulElem.appendChild(liElem);
        }
        return ulElem;
      }

      // Create menu with Farama projects by using the API at farama.org/api/projects.json
      const createCORSRequest = (method, url) => {
        let xhr = new XMLHttpRequest();
        xhr.responseType = 'json';

        if ("withCredentials" in xhr) {
          xhr.open(method, url, true);
        } else if (typeof XDomainRequest != "undefined") {
          // IE8 & IE9
          xhr = new XDomainRequest();
          xhr.open(method, url);
        } else {
          // CORS not supported.
          xhr = null;
        }
        return xhr;
      };

      const url = 'https://farama.org/api/projects.json';
      const imagesBasepath = "https://farama.org/assets/images"
      const method = 'GET';
      let xhr = createCORSRequest(method, url);

      xhr.onload = () => {
        const jsonResponse = xhr.response;
        const sections = {
          "Core Projects": [],
          "Mature Projects": {
            "Documentation": [],
            "Repositories": [],
          },
          "Incubating Projects": {
            "Documentation": [],
            "Repositories": [],
          },
          "Foundation": [
            {
              name: "About",
              link: "https://farama.org/about"
            },
            {
              name: "Standards",
              link: "https://farama.org/project_standards",
            },
            {
              name: "Donate",
              link: "https://farama.org/donations"
            }
          ]
        }

        // Categorize projects
        Object.keys(jsonResponse).forEach(key => {
          projectJson = jsonResponse[key];
          if (projectJson.website !== null) {
            projectJson.link = projectJson.website;
          } else {
            projectJson.link = projectJson.github;
          }
          if (projectJson.type === "core") {
            sections["Core Projects"].push(projectJson)
          } else if (projectJson.type == "mature") {
            if (projectJson.website !== null) {
              sections["Mature Projects"]["Documentation"].push(projectJson)
            } else {
              sections["Mature Projects"]["Repositories"].push(projectJson)
            }
          } else {
            if (projectJson.website !== null) {
              sections["Incubating Projects"]["Documentation"].push(projectJson)
            } else {
              sections["Incubating Projects"]["Repositories"].push(projectJson)
            }
          }
        })

        const menuContainer = document.querySelector(".farama-header-menu__body");

        Object.keys(sections).forEach((key, i) => {
          const sectionElem = Object.assign(
            document.createElement('div'), {
              className:'farama-header-menu__section',
            }
          )
          sectionElem.appendChild(Object.assign(document.createElement('span'),
            {
              className:'farama-header-menu__section-title' ,
              innerText: key
            }
          ))
          // is not a list
          if (sections[key].constructor !== Array) {
            const subSections = sections[key];
            const subSectionContainerElem = Object.assign(
                document.createElement('div'), {
                  className:'farama-header-menu__subsections-container',
                  style: 'display: flex'
                }
            )
            Object.keys(subSections).forEach((subKey, i) => {
              const subSectionElem = Object.assign(
                document.createElement('div'), {
                  className:'farama-header-menu__subsection',
                }
              )
              subSectionElem.appendChild(Object.assign(document.createElement('span'),
                {
                  className:'farama-header-menu__subsection-title' ,
                  innerText: subKey
                }
              ))
              const ulElem = createProjectsList(subSections[subKey], key !== 'Foundation');
              subSectionElem.appendChild(ulElem);
              subSectionContainerElem.appendChild(subSectionElem);
            })
            sectionElem.appendChild(subSectionContainerElem);
          } else {
            const projects = sections[key];
            const ulElem = createProjectsList(projects, true);
            sectionElem.appendChild(ulElem);
          }
          menuContainer.appendChild(sectionElem)
        });
      }

      xhr.onerror = function() {
        console.error("Unable to load projects");
      };

      xhr.send();
    </script>

    
    <script>
      const versioningConfig = {
        githubUser: 'Farama-Foundation',
        githubRepo: 'PettingZoo',
      };
      fetch('/main/_static/versioning/versioning_menu.html').then(response => {
        if (response.status === 200) {
            response.text().then(text => {
                const container = document.createElement("div");
                container.innerHTML = text;
                document.querySelector("body").appendChild(container);
                // innerHtml doenst evaluate scripts, we need to add them dynamically
                Array.from(container.querySelectorAll("script")).forEach(oldScript => {
                    const newScript = document.createElement("script");
                    Array.from(oldScript.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value));
                    newScript.appendChild(document.createTextNode(oldScript.innerHTML));
                    oldScript.parentNode.replaceChild(newScript, oldScript);
                });
            });
        } else {
            console.warn("Unable to load versioning menu", response);
        }
      });
    </script>

    </body>
</html>